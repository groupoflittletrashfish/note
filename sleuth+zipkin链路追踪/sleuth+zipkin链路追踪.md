## 简介
* 大型分布式微服务系统中，一个系统被拆分成N多个模块，这些模块负责不同的功能，组合成一套系统，最终可以提供丰富的功能。在这种分布式架构中，一次请求往往需要涉及到多个服务
* 服务之间的调用错综复杂，对于维护的成本成倍增加，势必存在以下几个问题：
  * 服务之间的依赖与被依赖的关系如何能够清晰的看到？
  * 出现异常时如何能够快速定位到异常服务？
  * 出现性能瓶颈时如何能够迅速定位哪个服务影响的？
* 为了能够在分布式架构中快速定位问题，分布式链路追踪应运而生。将一次分布式请求还原成调用链路，进行日志记录，性能监控并将一次分布式请求的调用情况集中展示。比如各个服务节点上的耗时、请求具体到达哪台机器上、每个服务节点的请求状态等等。

## Spring Cloud Sleuth
* Spring Cloud Sleuth实现了一种分布式的服务链路跟踪解决方案，通过使用Sleuth可以让我们快速定位某个服务的问题。简单来说，Sleuth相当于调用链监控工具的客户端，集成在各个微服务上，负责产生调用链监控数据。
* Spring Cloud Sleuth就提供了一套完整的服务跟踪的解决方案，在分布式系统中提供了追踪解决方案并且兼容支持了zipkin，Spring Cloud Sleuth负责对微服务调用链路的收集整理，而zipkin负责对链路的展现。

## Sleuth基本概念
* Span：基本的工作单元，相当于链表中的一个节点，通过一个唯一ID标记它的开始、具体过程和结束。我们可以通过其中存储的开始和结束的时间戳来统计服务调用的耗时。除此之外还可以获取事件的名称、请求信息等。
* Trace：一系列的Span串联形成的一个树状结构，当请求到达系统的入口时就会创建一个唯一ID（traceId），唯一标识一条链路。这个traceId始终在服务之间传递，直到请求的返回，那么就可以使用这个traceId将整个请求串联起来，形成一条完整的链路。
* Annotation：一些核心注解用来标注微服务调用之间的事件，重要的几个注解如下：
  * cs（Client Send）：客户端发出请求，开始一个请求的生命周期
  * sr（Server Received）：服务端接受请求并处理；sr-cs = 网络延迟 = 服务调用的时间
  * ss（Server Send）：服务端处理完毕准备发送到客户端；ss - sr = 服务器上的请求处理时间
  * cr（Client Reveived）：客户端接受到服务端的响应，请求结束； cr - sr = 请求的总时间

## ZipKin
* Zipkin 是 Twitter 的一个开源项目，它基于Google Dapper实现，它致力于收集服务的定时数据，以解决微服务架构中的延迟问题，包括数据的收集、存储、查找和展现。
* Zipkin共分为4个核心的组件，如下：
  * Collector：收集器组件，它主要用于处理从外部系统发送过来的跟踪信息，将这些信息转换为Zipkin内部处理的 Span 格式，以支持后续的存储、分析、展示等功能。
  * Storage：存储组件，它主要对处理收集器接收到的跟踪信息，默认会将这些信息存储在内存中，我们也可以修改此存储策略，通过使用其他存储组件将跟踪信息存储到数据库中
  * RESTful API：API 组件，它主要用来提供外部访问接口。比如给客户端展示跟踪信息，或是外接系统访问以实现监控等。
  * UI：基于API组件实现的上层应用。通过UI组件用户可以方便而有直观地查询和分析跟踪信息
* zipkin分为服务端和客户端，服务端主要用来收集跟踪数据并且展示，客户端主要功能是发送给服务端，微服务的应用也就是客户端，这样一旦发生调用，就会触发监听器将sleuth日志数据传输给服务端。

## Zipkin服务端的搭建
* 首先需要下载zin-server的jar包，由于网上很难找，这个地址能下载：https://pan.baidu.com/s/1-IhBSyGxdUc0yoRCvZK2Jw 密码：cxxa
* 下载完直接运行即可，java -jar
* 然后就可以访问 http://127.0.0.1:9411/了

## Zipkin客户端的搭建
* 其实也就是java代码
* 第一步当然是引入依赖，Zipkin中已经包含了Sleuth的依赖
    ~~~xml
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-starter-zipkin</artifactId>
    </dependency>
    ~~~
* 添加配置
    ~~~yaml
    spring:
    sleuth:
        sampler:
        # 采样率值介于0到1之间，1表示全部采集
        # 日志数据采样百分比，默认0.1(10%)，这里为了测试设置成了100%，生产环境只需要0.1即可
        probability: 0.1
    zipkin:
        # zipkin服务端地址
        base-url: http://127.0.0.1:9411
    ~~~
* 其实这样就已经完成了，然后发起请求后就可以查看到一个完整的链路的。但是就目前来看好像意义不大，还未学到精髓

## 数据采集的形式还有mysql持久化形式，MQ的形式，这个自行百度一下